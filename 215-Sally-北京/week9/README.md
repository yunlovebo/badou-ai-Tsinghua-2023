### 深度学习开源框架
1. 深度学习框架包含5个核心组件：
    1. 张量（Tensor）
    2. 基于张量的各种操作（Operation）
        1. 矩阵乘法
        2. 卷积
        3. 池化
        4. LSTM
    3. 计算图（Computation Graph）
        1. 概念：表示计算过程的流程图
        2. 作用：分析、理解神经网络
    4. 自动微分（Automatic Differentiation）工具
    5. BLAS、cuBLAS、cuDNN等拓展包
2. 主流深度学习框架4大阵营，前两个用的最多
    1. TensorFlow，前端框架Keras，背后巨头Google；
        1. TensorFlow里也有Keras
    2. PyTorch，前端框架FastAI，背后巨头Facebook；
    3. MXNet，前端框架Gluon，背后巨头Amazon；
        1. nlp领域，如讯飞在用
    4. Cognitive Toolkit (CNTK)，前端框架Keras或Gluon，背后巨头Microsoft。
        1. 推荐场景使用
3. 国内深度学习框架，前两个用的最多
    1. 华为MindSpore
        1. 支持端、边、云独立的和协同的统一训练和推理框架。2020年3月28日，正式开源（半开源，未完全开源）
        2. 仅支持华为生态
    2. 百度PaddlePaddle
        1. PaddlePaddle 100% 都在Github上公开，没有内部版本。PaddlePaddle能够应用于自然语言处理、图像识别、推荐引擎等多个领域，其优势在于开放的多个领先的预训练中文模型。
    3. 阿里巴巴XDL (X-Deep Learning)
        1. 阿里妈妈将把其应用于自身广告业务的算法框架XDL (X-DeepLearning)进行开源。XDL主要是针对特定应用场景如广告的深度学习问题的解决方案，是上层高级API框架而不是底层框架。XDL需要采用桥接的方式配合使用 TensorFlow 和 MXNet 作为单节点的计算后端，XDL依赖于阿里提供特定的部署环境。
    4. 小米MACE：
        1. 它针对移动芯片特性进行了大量优化，目前在小米手机上已广泛应用，如人像模式、场景识别等。该框架采用与 Caffe2 类似的描述文件定义模型，因此它能非常便捷地部署移动端应用。目前该框架为 TensorFlow 和 Caffe 模型提供转换工具，并且其它框架定义的模型很快也能得到支持。
4. 注意区分框架、模型、算法
    1. 任何框架都可以实现特定的模型
    2. 99.9的Layer都被主流框架支持
    3. 深度学习框架和模型、算法没有直接联系，没有一一对应的关系
    4. 一个框架训练出的模型不能在另一个框架上去推理，因为存储格式不兼容
5. 深度学习框架的标准化--ONNX，
    1. 解决框架间不兼容的问题，把不同框架训练出的模型都转成此第三方格式
    2. 开放神经网络交换（ONNX，“Open Neural Network Exchange”）：ONNX最初由微软和Facebook联合发布，后来亚马逊也加入进来，并发布了V1版本，宣布支持ONNX的公司还有AMD、ARM、华为、 IBM、英特尔、Qualcomm等。
    3. ONNX是一个表示深度学习模型的开放格式。它使用户可以更轻松地在不同框架之间转移模型。例如，它允许用户构建一个PyTorch模型，然后使用MXNet运行该模型来进行推理。

### Tensorflow
1. 基本用法
    1. 使用图 (graph) 来表示计算任务.
    2. 在被称之为 会话 (Session) 的上下文 (context) 中执行图.
        1. Session.run 是区分 1.x 和 2.x 的关键
    3. 使用 tensor 表示数据.
    4. 通过 变量 (Variable) 维护状态.
    5. 使用 feed 和 fetch 可以为任意的操作(arbitrary operation)赋值或者从其中获取数据。
2. 过程概览
    1. TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写)。一个 op 获得 0 个或多个 Tensor。执行计算, 产生 0 个或多个 Tensor。
    2. 每个 Tensor 是一个类型化的多维数组。例如,你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是 [batch, height, width, channels].
        1. 张量表示：N*H*W*C
    3. 一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话 里被启动.
        1. Session.run，在1.x版本里才有
    4. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法.
        1. 即调用推理和训练
    5. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是numpy ndarray对象。
3. 特别注意：
    1. 通道问题：不同的视觉库对于退休读取的方式不一样，图像的通道也不一样
        1. opencv的默认imread就是H*W*C
        2. Pytorch的Tensor为C*H*W
        3. Tensor两者都支持
4. 构件图
    1. 创建源op：源op不需要任何输入。例如常量（constant）。源op的输出被传递给其他op做运算。
    2. 在会话（session）中启动图
    3. 关闭session以释放资源 - 对应1.x
    4. 构建图的运算过程输出的结果是一个Tensor
5. 张量
    1. Name：代表的是张量的名字，也是张量的唯一标识符，我们可以在每个op上添加name属性来对节点进行命名，Name的值表示的是该张量来自于第几个输出结果（编号从0开始）。
    2. Shape：代表的是张量的维度。
    3. Type：表示的是张量的类型，每个张量都会有唯一的类型。我们需要注意的是要保证参与运算的张量类型相一致，否则会出现类型不匹配的错误。
    4. 常见的张量类型
        1. 是一个可优化的点，如：高位转地位
        2. 定点数、浮点数：精度、表示范围
6. 变量（Variables）
    1. 变量Variables维护图执行过程中的状态信息.
    2. 通常会将一个统计模型中的参数表示为一组变量.
        1. 例如, 你可以将一个神经网络的权重作为某个变量存储在一个 tensor 中. 在训练过程中, 通过重复运行训练图, 更新这个 tensor.
7. fetch/Feed
    1. Fetch：为了取回操作的输出内容，可以使用session对象的run()调用执行图时，传入一些tensor，这些tensor会帮助你取回结果。
        1. 只运行一遍就可以取到所有的值，提高效率，节省资源
    2. Feed：
        1. Feed：使用一个tensor值临时替换一个操作的输出结果。可以提供feed数据作为run()调用的参数.
        2. feed 只在调用它的方法内有效, 方法结束, feed 就会消失. 最常见的用例是将某些特殊的操作指定为“feed” 操作, 标记的方法是使用 tf.placeholder() 为这些操作创建占位符。
        3. placeholder是一个数据初始化的容器，它与变量最大的不同在于placeholder定义的是一个模板，这样我们就可以在session运行阶段，利用feed_dict的字典结构给placeholder填充具体的内容，而无需每次都提前定义好变量的值，大大提高了代码的利用率。
8. 扩展：
    1. 可视化工具TensorBoard
    2. CNMon：寒武纪硬件监测器工具

### Pytorch
1. 简介：
    1. Pytorch是torch的python版本，是由Facebook开源的神经网络框架，专门针对 GPU 加速的深度神经网络（DNN）编程。Torch 是一个经典的对多维矩阵数据进行操作的张量（tensor）库，在机器学习和其他数学密集型应用有广泛应用。
    2. Pytorch的计算图是动态的（更灵活），可以根据计算需要实时改变计算图。
    3. 由于Torch语言采用 Lua，导致在国内一直很小众，并逐渐被支持 Python 的 Tensorflow 抢走用户。作为经典机器学习库 Torch 的端口，PyTorch 为 Python 语言使用者提供了舒适的写代码选择。
    4. 这是一个基于Python的科学计算包，其旨在服务两类场合：
        1. 替代numpy发挥GPU潜能
        2. 一个提供了高度灵活性和效率的深度学习实验性平台
2. 优势：
    1. 简洁：PyTorch的设计追求最少的封装，尽量避免重复造轮子。不像 TensorFlow 中充斥着session、graph、operation、name_scope、variable、tensor、layer等全新的概念，PyTorch 的设计遵循tensor→variable(autograd)→nn.Module三个由低到高的抽象层次，分别代表高维数组（张量）、自动求导（变量）和神经网络（层/模块），而且这三个抽象之间联系紧密，可以同时进行修改和操作。
    2. 速度：PyTorch 的灵活性不以速度为代价，在许多评测中，PyTorch 的速度表现胜过 TensorFlow和 Keras 等框架。
    3. 易用：PyTorch 是所有的框架中面向对象设计的最优雅的一个。PyTorch的面向对象的接口设计来源于Torch，而Torch的接口设计以灵活易用而著称，Keras作者最初就是受Torch的启发才开发了Keras。
    4. 活跃的社区：PyTorch 提供了完整的文档，循序渐进的指南，作者亲自维护的论坛，供用户交流和求教问题。Facebook 人工智能研究院对 PyTorch 提供了强力支持。
3. 常用工具包
    1. torch ：类似 NumPy 的张量库，支持GPU；
    2. torch.autograd ：基于 type 的自动区别库，支持 torch 之中的所有可区分张量运行；
    3. torch.nn ：为最大化灵活性而设计，与 autograd 深度整合的神经网络库；
    4. torch.optim：与 torch.nn 一起使用的优化包，包含 SGD、RMSProp、LBFGS、Adam 等标准优化
    方式；
    5. torch.multiprocessing： python 多进程并发，进程之间 torch Tensors 的内存共享；
    6. torch.utils：数据载入器。具有训练器和其他便利功能；
    7. torch.legacy(.nn/.optim) ：出于向后兼容性考虑，从 Torch 移植来的 legacy 代码；
4. 特别注意：通道问题
    1. 不同的视觉库对于图像读取的方式不一样，图像的通道也不一样：
    2. opencv的默认imread就是H*W*C，Pytorch的Tensor为C*H*W，TensorFlow两者都支持。
5. 理解pytorch的基础主要从以下三个方面
    1. Numpy风格的Tensor操作。pytorch中tensor提供的API参考了Numpy的设计。
    2. 变量自动求导。在一序列计算过程形成的计算图中，参与的变量可以方便的计算自己对目标函数的梯度。
    3. 神经网络层与损失函数优化等高层封装。网络层的封装存在于torch.nn模块，损失函数由torch.nn.functional模块提供，优化函数由torch.optim模块提供。
6. 在pytorch中就只需要分三步：
    1. 写好网络；
    2. 编写数据的标签和路径索引；
    3. 把数据送到网络。

### 算法优化
1. 名词：
    1. original-loss：原始的loss
    2. minibatch-loss：在minibatch上的loss
    3. BGD：原始的梯度下降法
    4. SGD：minibatch上的梯度
2. SGD（随机梯度下降）
    1. SGD 又称 online 的梯度下降， 每次估计梯度的时候， 只选用一个或几个batch训练样本。
    2. 每次随机选择一个mini-batch去计算梯度，每走一步只需要遍历一个minibatch（一～几百）的数据。
    3. 缺点
        1. mini-batch SGD训练算法在到达最优点的时候并不能够总是真正到达最优点，而是在最优点附近徘徊。
        2. 需要我们挑选一个合适的学习率
            1. 采用小的学习率的时候，会导致网络在训练的时候收敛太慢
            2. 采用大的学习率的时候，会导致在训练过程中优化的幅度跳过函数的范围，也就是可能跳过最优点。
3. Momentum：基于SGD缺点的进一步改进
    1. 我们所希望的仅仅是网络在优化的时候网络的损失函数有一个很好的收敛速度，同时又不至于摆动幅度太大。
    2. 利用梯度动量，经过一系列复杂的公式计算，让梯度的摆动幅度变小

### 卷积神经网络
1. 概论
    1. CNN就是著名的卷积神经网络，是一种前馈神经网络。
    2. CNN不同于传统的神经网络只有线性连接，CNN包括卷积（convolution）操作、汇合或池化（pooling）
    3. 操作和非线性激活函数映射（即线性连接）等等。
    4. 经典的CNN网络有Alex-Net、VGG-Nets、Resnet等。
    5. 应用：
        1. 深度学习在计算机图像识别上的应用非常成功。
        2. 利用深度学习，我们能够对图片进行高精度识别，实现这一功能的，主要依靠神经网络中的一种分支，名为卷积网络。
        3. 卷积网络与我们前面实现的网络不同之处在于，它可以直接接受多维向量，而我们以前实现的网络只能接收一维向量。
2. 三通道卷积
    1. 不需要reshape成一维，例如一个图片可以直接做三通道卷积
3. 卷积神经网络（CNN）
    1. 卷积神经网络，是在传统的神经网络之上加了一些层
    2. 卷积的作用：特征提取
    3. 如手写数字识别的项目中，空白点太多了，传进去可能引起过拟合，所以先卷积提取特征，再传给FC(全连接)去做分类
    4. 总结：卷积神经网络 = 特征提取网 + 分类网络
        1. 卷积提取特征
        2. 分类还是传统神经网络的FC
4. 池化层 - pool
    1. 举例：Max pool
        1. 也有kernel的概念，一般是2 * 2
        2. 也有窗口滑动的过程
        3. Max pool 求得是每一块的最大值，如果是平均值kernel，则取每一块的平均值
    2. 池化的作用：
        1. 卷积操作产生了太多的数据，如果没有max pooling对这些数据进行压缩，那么网络的运算量将会非常巨大，而且数据参数过于冗余就非常容易导致过度拟合。
        2. 即降维
    3. 会造成数据丢失吗？- 会，但留下的数据保证是最有影响的数据
5. 卷积神经网络分类过程的感性认识：
    1. 当我们的图片（黑白图片厚度为1 ，彩色图片厚度为3）输入到神经网络后，我们会通过卷积神经网络将图片的长和宽进行压缩，然后把厚度增加。
        1. 厚度指的是一个个的特征，也是channel
    2. 最后就变成了一个长宽很小，厚度很高的像素块。然后结果放入传统的神经网络（全连接）中处理，最后链接一个分类器（比如softmax），从而分辨出图片是什么。
6. 卷积核
    1. 如果不是由人来设计一个滤波器，而是从一个随机滤波器开始，根据某种目标、用某种方法去逐渐调整它，直到它接近我们想要的样子，可行么？
    2. 这就是卷积神经网络（Convolutional Neural Network, CNN）的思想了。
    3. 可调整的滤波器是CNN的“卷积”那部分；如何调整滤波器则是CNN的“神经网络”那部分（训练）。
    4. 如果卷积核大到和原始图像一样，那就退化成全连接了；所以全连接是卷积的一个特例


TODO：作业：
1. tf实现简单神经网络
2. pytorch实现手写数字识别
